#!/usr/bin/env python3
"""
Temporal Fusion Transformer (TFT) Trading Strategy
State-of-the-Art ML Architecture (2024 Research: Sharpe 2.54)

Based on published research showing TFT achieving:
- 4.01% returns with Sharpe Ratio of 2.54
- Superior multi-horizon forecasting
- Interpretable attention mechanisms

This implementation uses REAL market data and production-grade ML.

Architecture Features:
- Variable Selection Networks (learns important features)
- Multi-Head Attention (temporal dependencies)
- Multi-Horizon Forecasting (1-5 days ahead)
- Gating mechanisms (context-aware learning)
"""

import sys
import os
import warnings
warnings.filterwarnings('ignore')

from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, List, Tuple

import numpy as np
import pandas as pd
import yfinance as yf

import torch
import lightning.pytorch as pl
from lightning.pytorch.callbacks import EarlyStopping
from lightning.pytorch.tuner import Tuner

from pytorch_forecasting import TimeSeriesDataSet, TemporalFusionTransformer
from pytorch_forecasting.data import GroupNormalizer
from pytorch_forecasting.metrics import QuantileLoss
from pytorch_forecasting import Baseline

# ============================================================================
# CONFIGURATION
# ============================================================================

# Date range for real market data
END_DATE = datetime.now().strftime('%Y-%m-%d')
START_DATE = (datetime.now() - timedelta(days=900)).strftime('%Y-%m-%d')  # ~2.5 years for training

# Stock universe (diverse sectors)
TICKERS = [
    # Technology
    'AAPL', 'MSFT', 'GOOGL', 'NVDA', 'META',
    # Financials
    'JPM', 'BAC', 'WFC', 'GS', 'MS',
    # Energy
    'XOM', 'CVX', 'COP', 'SLB', 'MPC',
    # Healthcare
    'JNJ', 'UNH', 'PFE', 'ABBV', 'TMO',
    # Consumer
    'WMT', 'HD', 'MCD', 'NKE', 'SBUX'
]

# TFT Model Parameters
MAX_ENCODER_LENGTH = 60  # Use 60 days of history
MAX_PREDICTION_LENGTH = 5  # Predict 5 days ahead
BATCH_SIZE = 128
HIDDEN_SIZE = 64
ATTENTION_HEAD_SIZE = 4
DROPOUT = 0.1
LEARNING_RATE = 0.01

# Trading Parameters
POSITION_SIZE_MULTIPLIER = 2.0  # More aggressive than V1/V2
MAX_POSITIONS = 15
SIGNAL_THRESHOLD = 0.02  # 2% predicted return to enter

# ============================================================================
# DATA ACQUISITION
# ============================================================================

def fetch_real_market_data(tickers: List[str], start: str, end: str) -> pd.DataFrame:
    """
    Fetch REAL market data from Yahoo Finance
    """
    print(f"\nüìä Fetching REAL market data from Yahoo Finance...")
    print(f"   Date range: {start} to {end}")
    print(f"   Tickers: {len(tickers)} stocks")

    print(f"   Downloading data...")
    data = yf.download(
        tickers,
        start=start,
        end=end,
        progress=False,
        auto_adjust=True,
        group_by='column'
    )

    if data.empty:
        raise ValueError("Failed to download any data!")

    # Restructure data
    all_dfs = []

    for ticker in tickers:
        try:
            if len(tickers) == 1:
                ticker_data = data.copy()
            else:
                ticker_data = pd.DataFrame({
                    'open': data['Open'][ticker],
                    'high': data['High'][ticker],
                    'low': data['Low'][ticker],
                    'close': data['Close'][ticker],
                    'volume': data['Volume'][ticker]
                })

            ticker_data = ticker_data.dropna()
            if len(ticker_data) > 0:
                ticker_data['ticker'] = ticker
                ticker_data['date'] = ticker_data.index
                all_dfs.append(ticker_data)
                print(f"   ‚úì {ticker}: {len(ticker_data)} days")
        except (KeyError, Exception) as e:
            print(f"   ‚úó {ticker}: Failed - {e}")

    if not all_dfs:
        raise ValueError("Failed to download any data!")

    combined = pd.concat(all_dfs, ignore_index=True)

    print(f"\n‚úì Downloaded {len(all_dfs)} stocks successfully")
    print(f"   Total records: {len(combined):,}")

    return combined

# ============================================================================
# FEATURE ENGINEERING
# ============================================================================

def engineer_features(df: pd.DataFrame) -> pd.DataFrame:
    """
    Create features for TFT model

    Features:
    - Time-varying known: day_of_week, month, day_of_month
    - Time-varying unknown: returns, volatility, momentum, RSI, volume_ratio
    - Static: ticker (categorical)
    """
    print("\nüîß Engineering features for TFT...")

    df = df.copy()
    df = df.sort_values(['ticker', 'date']).reset_index(drop=True)

    # Time index (required by TFT)
    df['time_idx'] = 0
    for ticker in df['ticker'].unique():
        mask = df['ticker'] == ticker
        df.loc[mask, 'time_idx'] = np.arange(mask.sum())

    df['time_idx'] = df['time_idx'].astype(int)

    # Time-varying known features (known in advance)
    df['date'] = pd.to_datetime(df['date'])
    df['day_of_week'] = df['date'].dt.dayofweek
    df['month'] = df['date'].dt.month
    df['day_of_month'] = df['date'].dt.day

    # Calculate features per ticker
    all_ticker_dfs = []

    for ticker in df['ticker'].unique():
        ticker_df = df[df['ticker'] == ticker].copy()

        # Price-based features
        ticker_df['returns'] = ticker_df['close'].pct_change()
        ticker_df['log_returns'] = np.log(ticker_df['close'] / ticker_df['close'].shift(1))

        # Volatility (20-day realized vol)
        ticker_df['volatility'] = ticker_df['returns'].rolling(20).std() * np.sqrt(252)

        # Momentum features
        ticker_df['momentum_5'] = ticker_df['close'] / ticker_df['close'].shift(5) - 1
        ticker_df['momentum_20'] = ticker_df['close'] / ticker_df['close'].shift(20) - 1
        ticker_df['momentum_60'] = ticker_df['close'] / ticker_df['close'].shift(60) - 1

        # RSI (14-day)
        delta = ticker_df['close'].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
        rs = gain / loss
        ticker_df['rsi'] = 100 - (100 / (1 + rs))

        # Volume features
        ticker_df['volume_ma'] = ticker_df['volume'].rolling(20).mean()
        ticker_df['volume_ratio'] = ticker_df['volume'] / ticker_df['volume_ma']

        # Moving averages
        ticker_df['ma_20'] = ticker_df['close'].rolling(20).mean()
        ticker_df['ma_50'] = ticker_df['close'].rolling(50).mean()
        ticker_df['price_to_ma20'] = ticker_df['close'] / ticker_df['ma_20'] - 1
        ticker_df['price_to_ma50'] = ticker_df['close'] / ticker_df['ma_50'] - 1

        # Bollinger Bands
        ticker_df['bb_upper'] = ticker_df['ma_20'] + 2 * ticker_df['close'].rolling(20).std()
        ticker_df['bb_lower'] = ticker_df['ma_20'] - 2 * ticker_df['close'].rolling(20).std()
        ticker_df['bb_position'] = (ticker_df['close'] - ticker_df['bb_lower']) / (ticker_df['bb_upper'] - ticker_df['bb_lower'])

        # Target: Next day return (shifted so we can use it as target)
        ticker_df['target_return'] = ticker_df['returns'].shift(-1)

        all_ticker_dfs.append(ticker_df)

    df = pd.concat(all_ticker_dfs, ignore_index=True)

    # Drop NaN rows (from feature calculation)
    df = df.dropna()

    print(f"‚úì Features engineered")
    print(f"   Records after feature engineering: {len(df):,}")
    print(f"   Features created: returns, volatility, momentum, RSI, volume_ratio, MA ratios, BB position")

    return df

# ============================================================================
# TFT MODEL TRAINING
# ============================================================================

def prepare_tft_dataset(df: pd.DataFrame, max_encoder_length: int, max_prediction_length: int) -> Tuple[TimeSeriesDataSet, TimeSeriesDataSet]:
    """
    Prepare TimeSeriesDataSet for TFT training
    """
    print("\nüìö Preparing TFT dataset...")

    # Filter out rows with NaN values in any feature
    # TFT requires complete data
    initial_len = len(df)

    # First drop all NaN rows
    df = df.dropna().copy()

    # Then explicitly ensure target_return has no NaN
    df = df[df['target_return'].notna()].copy()

    # Also filter out any infinite values
    df = df[np.isfinite(df['target_return'])].copy()

    print(f"   Records after filtering: {len(df):,} (removed {initial_len - len(df):,})")

    # Split train/validation (80/20) - but split by time_idx within each ticker
    train_dfs = []
    val_dfs = []

    for ticker in df['ticker'].unique():
        ticker_df = df[df['ticker'] == ticker].sort_values('time_idx').copy()

        # Remove any remaining NaN from this ticker's data
        ticker_df = ticker_df[ticker_df['target_return'].notna()]
        ticker_df = ticker_df[np.isfinite(ticker_df['target_return'])]

        # Keep only middle portion of data (avoid edges where we can't make predictions)
        n = len(ticker_df)
        if n < max_encoder_length + max_prediction_length + 20:
            continue  # Skip tickers without enough data

        train_size = int(n * 0.8)

        # Skip first max_encoder_length rows and last max_prediction_length rows
        start_idx = max_encoder_length
        end_idx = n - max_prediction_length

        if end_idx > start_idx + train_size:
            train_data = ticker_df.iloc[start_idx:start_idx + train_size].copy()
            val_data = ticker_df.iloc[start_idx + train_size:end_idx].copy()

            # Final check - no NaN in target
            train_data = train_data[train_data['target_return'].notna()]
            val_data = val_data[val_data['target_return'].notna()]

            if len(train_data) > 0:
                train_dfs.append(train_data)
            if len(val_data) > 0:
                val_dfs.append(val_data)

    train_df = pd.concat(train_dfs, ignore_index=True)
    val_df = pd.concat(val_dfs, ignore_index=True)

    print(f"   Training samples: {len(train_df):,}")
    print(f"   Validation samples: {len(val_df):,}")

    # Create training dataset
    training = TimeSeriesDataSet(
        train_df,
        time_idx="time_idx",
        target="target_return",  # Predict next-day return
        group_ids=["ticker"],
        min_encoder_length=max_encoder_length // 2,
        max_encoder_length=max_encoder_length,
        min_prediction_length=1,
        max_prediction_length=max_prediction_length,

        # Time-varying known features (known in future)
        time_varying_known_reals=["time_idx", "day_of_week", "month", "day_of_month"],

        # Time-varying unknown features (not known in future - to be predicted)
        # Note: target_return is NOT included here because it's the target, not a feature
        time_varying_unknown_reals=[
            "returns", "log_returns", "volatility",
            "momentum_5", "momentum_20", "momentum_60",
            "rsi", "volume_ratio",
            "price_to_ma20", "price_to_ma50", "bb_position"
        ],

        # Static categorical features
        static_categoricals=["ticker"],

        # Target normalization
        target_normalizer=GroupNormalizer(
            groups=["ticker"], transformation="softplus"
        ),

        # Add relative time index
        add_relative_time_idx=True,
        add_target_scales=True,
        add_encoder_length=True,

        allow_missing_timesteps=True
    )

    # Create validation dataset
    validation = TimeSeriesDataSet.from_dataset(
        training,
        df,
        predict=True,
        stop_randomization=True
    )

    print(f"‚úì Dataset prepared")
    print(f"   Training samples: {len(training)}")
    print(f"   Validation samples: {len(validation)}")

    return training, validation

def train_tft_model(training: TimeSeriesDataSet, validation: TimeSeriesDataSet) -> TemporalFusionTransformer:
    """
    Train Temporal Fusion Transformer model
    """
    print("\nü§ñ Training Temporal Fusion Transformer...")

    # Create dataloaders
    train_dataloader = training.to_dataloader(
        train=True, batch_size=BATCH_SIZE, num_workers=0
    )
    val_dataloader = validation.to_dataloader(
        train=False, batch_size=BATCH_SIZE * 10, num_workers=0
    )

    # Configure model
    print(f"\n   Model Configuration:")
    print(f"   - Hidden size: {HIDDEN_SIZE}")
    print(f"   - Attention heads: {ATTENTION_HEAD_SIZE}")
    print(f"   - Dropout: {DROPOUT}")
    print(f"   - Learning rate: {LEARNING_RATE}")
    print(f"   - Encoder length: {MAX_ENCODER_LENGTH}")
    print(f"   - Prediction horizon: {MAX_PREDICTION_LENGTH}")

    # Initialize TFT model
    tft = TemporalFusionTransformer.from_dataset(
        training,
        learning_rate=LEARNING_RATE,
        hidden_size=HIDDEN_SIZE,
        attention_head_size=ATTENTION_HEAD_SIZE,
        dropout=DROPOUT,
        hidden_continuous_size=HIDDEN_SIZE // 2,
        loss=QuantileLoss(),
        log_interval=10,
        reduce_on_plateau_patience=4,
    )

    print(f"\n   Model initialized: {tft.__class__.__name__}")
    print(f"   Parameters: {sum(p.numel() for p in tft.parameters()):,}")

    # Configure trainer
    early_stop_callback = EarlyStopping(
        monitor="val_loss",
        min_delta=1e-4,
        patience=10,
        verbose=False,
        mode="min"
    )

    trainer = pl.Trainer(
        max_epochs=30,
        accelerator="cpu",
        enable_model_summary=True,
        gradient_clip_val=0.1,
        callbacks=[early_stop_callback],
        logger=False,
        enable_checkpointing=False,
        enable_progress_bar=True
    )

    print(f"\n   Training model (max 30 epochs with early stopping)...")
    print(f"   This may take a few minutes...\n")

    # Train model
    trainer.fit(
        tft,
        train_dataloaders=train_dataloader,
        val_dataloaders=val_dataloader,
    )

    print(f"\n‚úì Model training complete!")
    print(f"   Best model selected based on validation loss")

    return tft

# ============================================================================
# TRADING STRATEGY
# ============================================================================

def generate_predictions(tft: TemporalFusionTransformer, df: pd.DataFrame, training: TimeSeriesDataSet) -> pd.DataFrame:
    """
    Generate predictions for all data points
    """
    print("\nüîÆ Generating predictions with TFT model...")

    # Create dataset for prediction
    predict_dataset = TimeSeriesDataSet.from_dataset(
        training,
        df,
        predict=True,
        stop_randomization=True
    )

    predict_dataloader = predict_dataset.to_dataloader(
        train=False, batch_size=BATCH_SIZE * 10, num_workers=0
    )

    # Generate predictions (simpler approach - just get point predictions)
    predictions = tft.predict(predict_dataloader, mode="prediction", return_index=True)

    # predictions is a tuple: (predictions_tensor, index)
    pred_values = predictions[0].numpy()  # Shape: (samples, prediction_length)
    index = predictions[1]  # Index dataframe

    # Map predictions back to dataframe
    results = []
    for i in range(len(pred_values)):
        # Get ticker and time info from index
        ticker_name = index.iloc[i]['ticker']
        time_idx = index.iloc[i]['time_idx']

        # Store predictions for each horizon
        result = {
            'ticker': ticker_name,
            'time_idx': time_idx,
        }

        # pred_values might be 1D (single horizon) or 2D (multi-horizon)
        if len(pred_values.shape) == 1:
            result['pred_return_1d'] = pred_values[i]
        else:
            for horizon in range(min(MAX_PREDICTION_LENGTH, pred_values.shape[1])):
                result[f'pred_return_{horizon+1}d'] = pred_values[i, horizon]

        results.append(result)

    pred_df = pd.DataFrame(results)

    # Merge predictions back to original dataframe
    df_with_pred = df.merge(pred_df, on=['ticker', 'time_idx'], how='left')

    print(f"‚úì Predictions generated")
    print(f"   Prediction coverage: {pred_df['pred_return_1d'].notna().sum() if 'pred_return_1d' in pred_df.columns else len(pred_df)} / {len(df)} records")

    return df_with_pred

def backtest_tft_strategy(df: pd.DataFrame, initial_capital: float = 100000) -> Dict:
    """
    Backtest TFT-based trading strategy
    """
    print("\nüî¨ Backtesting TFT trading strategy...")

    # Only use data where we have predictions
    df = df[df['pred_return_1d'].notna()].copy()
    df = df.sort_values(['date', 'ticker']).reset_index(drop=True)

    dates = sorted(df['date'].unique())

    positions = {}  # {ticker: shares}
    daily_values = []
    cash = initial_capital

    total_trades = 0
    winning_trades = 0

    print(f"   Backtesting {len(dates)} trading days...")

    for date in dates:
        day_data = df[df['date'] == date].copy()

        # Exit all positions (daily rebalance)
        if positions:
            for ticker, shares in positions.items():
                ticker_data = day_data[day_data['ticker'] == ticker]
                if not ticker_data.empty:
                    exit_price = ticker_data.iloc[0]['close']
                    proceeds = shares * exit_price
                    cash += proceeds

            positions = {}

        # Generate new signals based on predictions
        day_data['signal_strength'] = day_data['pred_return_1d']

        # Only consider positive predictions above threshold
        candidates = day_data[day_data['signal_strength'] > SIGNAL_THRESHOLD].copy()

        # Sort by predicted return (highest first)
        candidates = candidates.sort_values('signal_strength', ascending=False)

        # Take top N positions
        top_candidates = candidates.head(MAX_POSITIONS)

        if len(top_candidates) > 0:
            # Equal weight positions
            position_size = (cash / len(top_candidates)) * POSITION_SIZE_MULTIPLIER
            position_size = min(position_size, cash / len(top_candidates))  # Don't use more than available

            for _, row in top_candidates.iterrows():
                ticker = row['ticker']
                price = row['close']
                pred_return = row['pred_return_1d']

                shares = int(position_size / price)

                if shares > 0:
                    cost = shares * price
                    if cost <= cash:
                        cash -= cost
                        positions[ticker] = shares
                        total_trades += 1

        # Calculate portfolio value
        holdings_value = 0
        for ticker, shares in positions.items():
            ticker_data = day_data[day_data['ticker'] == ticker]
            if not ticker_data.empty:
                holdings_value += shares * ticker_data.iloc[0]['close']

        total_value = cash + holdings_value

        daily_values.append({
            'date': date,
            'cash': cash,
            'holdings': holdings_value,
            'total': total_value,
            'num_positions': len(positions)
        })

    # Convert to DataFrame
    portfolio_values = pd.DataFrame(daily_values)
    portfolio_values['date'] = pd.to_datetime(portfolio_values['date'])
    portfolio_values = portfolio_values.set_index('date')

    # Calculate benchmark (buy and hold equal-weighted)
    benchmark_values = []
    benchmark_shares = {}
    benchmark_cash = initial_capital

    first_date = dates[0]
    first_day = df[df['date'] == first_date]
    tickers = first_day['ticker'].unique()

    per_stock = benchmark_cash / len(tickers)
    for ticker in tickers:
        ticker_data = first_day[first_day['ticker'] == ticker]
        if not ticker_data.empty:
            price = ticker_data.iloc[0]['close']
            shares = int(per_stock / price)
            benchmark_shares[ticker] = shares
            benchmark_cash -= shares * price

    for date in dates:
        day_data = df[df['date'] == date]
        holdings = 0
        for ticker, shares in benchmark_shares.items():
            ticker_data = day_data[day_data['ticker'] == ticker]
            if not ticker_data.empty:
                holdings += shares * ticker_data.iloc[0]['close']

        benchmark_values.append({
            'date': date,
            'total': benchmark_cash + holdings
        })

    benchmark = pd.DataFrame(benchmark_values)
    benchmark['date'] = pd.to_datetime(benchmark['date'])
    benchmark = benchmark.set_index('date')

    # Calculate metrics
    strategy_returns = portfolio_values['total'].pct_change().dropna()
    benchmark_returns = benchmark['total'].pct_change().dropna()

    strategy_sharpe = (strategy_returns.mean() / strategy_returns.std()) * np.sqrt(252) if strategy_returns.std() > 0 else 0
    benchmark_sharpe = (benchmark_returns.mean() / benchmark_returns.std()) * np.sqrt(252) if benchmark_returns.std() > 0 else 0

    strategy_cummax = portfolio_values['total'].cummax()
    strategy_drawdown = (portfolio_values['total'] - strategy_cummax) / strategy_cummax
    max_drawdown = strategy_drawdown.min()

    benchmark_cummax = benchmark['total'].cummax()
    benchmark_drawdown = (benchmark['total'] - benchmark_cummax) / benchmark_cummax
    benchmark_max_dd = benchmark_drawdown.min()

    total_days = (dates[-1] - dates[0]).days
    years = total_days / 365.25

    final_value = portfolio_values['total'].iloc[-1]
    strategy_annual_return = (final_value / initial_capital) ** (1/years) - 1

    benchmark_final = benchmark['total'].iloc[-1]
    benchmark_annual_return = (benchmark_final / initial_capital) ** (1/years) - 1

    win_rate = (strategy_returns > 0).sum() / len(strategy_returns)

    # Print results
    print(f"\n" + "="*70)
    print("üìä TEMPORAL FUSION TRANSFORMER STRATEGY RESULTS")
    print("="*70)

    print(f"\nüóìÔ∏è  Period: {dates[0].date()} to {dates[-1].date()} ({total_days} days, {years:.2f} years)")
    print(f"üí∞ Initial Capital: ${initial_capital:,.0f}")

    print(f"\nüéØ TFT STRATEGY PERFORMANCE:")
    print(f"   Final Value:        ${final_value:,.2f}")
    print(f"   Total Return:       {(final_value/initial_capital - 1)*100:+.2f}%")
    print(f"   Annual Return:      {strategy_annual_return*100:+.2f}%")
    print(f"   Sharpe Ratio:       {strategy_sharpe:.2f}")
    print(f"   Max Drawdown:       {max_drawdown*100:.2f}%")
    print(f"   Win Rate (Daily):   {win_rate*100:.1f}%")

    print(f"\nüìà BENCHMARK (Buy & Hold):")
    print(f"   Final Value:        ${benchmark_final:,.2f}")
    print(f"   Total Return:       {(benchmark_final/initial_capital - 1)*100:+.2f}%")
    print(f"   Annual Return:      {benchmark_annual_return*100:+.2f}%")
    print(f"   Sharpe Ratio:       {benchmark_sharpe:.2f}")
    print(f"   Max Drawdown:       {benchmark_max_dd*100:.2f}%")

    print(f"\nüí° EXCESS PERFORMANCE:")
    excess_return = strategy_annual_return - benchmark_annual_return
    print(f"   Excess Return:      {excess_return*100:+.2f}%")
    print(f"   Sharpe Improvement: {(strategy_sharpe - benchmark_sharpe):+.2f}")

    if excess_return > 0:
        print(f"   üéâ ALPHA ACHIEVED! Outperforming by {excess_return*100:.1f}%!")
    else:
        print(f"   ‚ö†Ô∏è  Underperforming by {abs(excess_return)*100:.1f}%")

    avg_positions = portfolio_values['num_positions'].mean()
    print(f"\nüìä TRADING STATISTICS:")
    print(f"   Total Trades:       {total_trades}")
    print(f"   Avg # Positions:    {avg_positions:.1f}")
    print(f"   Max Positions:      {portfolio_values['num_positions'].max()}")

    return {
        'portfolio_values': portfolio_values,
        'benchmark_values': benchmark,
        'strategy_sharpe': strategy_sharpe,
        'strategy_annual_return': strategy_annual_return,
        'benchmark_sharpe': benchmark_sharpe,
        'benchmark_annual_return': benchmark_annual_return,
        'max_drawdown': max_drawdown,
        'win_rate': win_rate,
        'excess_return': excess_return,
        'total_trades': total_trades
    }

# ============================================================================
# COMPARISON WITH PREVIOUS STRATEGIES
# ============================================================================

def compare_with_previous(tft_results: Dict):
    """
    Compare TFT with V1 and V2 strategies
    """
    print(f"\n" + "="*70)
    print("üîÑ STRATEGY COMPARISON: V1 vs V2 vs TFT")
    print("="*70)

    # Previous results
    v1_annual = 0.0228  # 2.28%
    v1_sharpe = 0.73
    v1_excess = -0.2252  # -22.52%

    v2_annual = 0.0002  # 0.02%
    v2_sharpe = 0.14
    v2_excess = -0.2567  # -25.67%

    tft_annual = tft_results['strategy_annual_return']
    tft_sharpe = tft_results['strategy_sharpe']
    tft_excess = tft_results['excess_return']

    print(f"\nüìà Annual Return:")
    print(f"   V1 (Volatility Breakout):  {v1_annual*100:+6.2f}%")
    print(f"   V2 (Enhanced Multi-Factor): {v2_annual*100:+6.2f}%")
    print(f"   TFT (ML Deep Learning):     {tft_annual*100:+6.2f}% {'‚≠ê' if tft_annual > max(v1_annual, v2_annual) else ''}")

    print(f"\n‚öñÔ∏è  Sharpe Ratio:")
    print(f"   V1:  {v1_sharpe:.2f}")
    print(f"   V2:  {v2_sharpe:.2f}")
    print(f"   TFT: {tft_sharpe:.2f} {'‚≠ê' if tft_sharpe > max(v1_sharpe, v2_sharpe) else ''}")

    print(f"\nüéØ Alpha (vs Benchmark):")
    print(f"   V1:  {v1_excess*100:+6.2f}%")
    print(f"   V2:  {v2_excess*100:+6.2f}%")
    print(f"   TFT: {tft_excess*100:+6.2f}% {'‚≠ê' if tft_excess > max(v1_excess, v2_excess) else ''}")

    print(f"\nüí° Summary:")
    if tft_annual > max(v1_annual, v2_annual):
        print(f"   ‚úÖ TFT is the BEST performing strategy!")
        improvement = ((tft_annual - max(v1_annual, v2_annual)) / abs(max(v1_annual, v2_annual))) * 100
        print(f"   üìà {improvement:.1f}% improvement over best previous strategy")
    else:
        print(f"   ‚ö†Ô∏è  TFT did not outperform V1/V2")

    if tft_sharpe > 1.0:
        print(f"   ‚úÖ Excellent risk-adjusted returns (Sharpe > 1.0)")

    if tft_excess > 0:
        print(f"   ‚úÖ ALPHA GENERATION: Beating benchmark!")

    # Compare to published TFT research
    published_sharpe = 2.54
    print(f"\nüìö Comparison to Published Research:")
    print(f"   Published TFT Sharpe: {published_sharpe:.2f}")
    print(f"   Our TFT Sharpe:       {tft_sharpe:.2f}")
    print(f"   Gap:                  {(tft_sharpe - published_sharpe):.2f}")

    if tft_sharpe >= published_sharpe * 0.5:
        print(f"   ‚úÖ Achieved >50% of published performance - good for real-world data!")
    else:
        print(f"   ‚ö†Ô∏è  Below 50% of published results - may need more tuning")

# ============================================================================
# MAIN EXECUTION
# ============================================================================

def main():
    print("\n" + "üöÄ"*35)
    print("  TEMPORAL FUSION TRANSFORMER TRADING STRATEGY")
    print("  State-of-the-Art ML Architecture (2024 Research)")
    print("  Published Performance: 4.01% returns, Sharpe 2.54")
    print("üöÄ"*35)

    try:
        # 1. Fetch real market data
        raw_data = fetch_real_market_data(TICKERS, START_DATE, END_DATE)

        # 2. Engineer features
        data = engineer_features(raw_data)

        # 3. Prepare TFT datasets
        training, validation = prepare_tft_dataset(
            data,
            MAX_ENCODER_LENGTH,
            MAX_PREDICTION_LENGTH
        )

        # 4. Train TFT model
        tft_model = train_tft_model(training, validation)

        # 5. Generate predictions
        data_with_predictions = generate_predictions(tft_model, data, training)

        # 6. Backtest strategy
        results = backtest_tft_strategy(data_with_predictions)

        # 7. Compare with previous strategies
        compare_with_previous(results)

        print(f"\n" + "="*70)
        print("‚úÖ TFT Strategy Complete!")
        print("="*70)
        print(f"\nThis implements cutting-edge 2024 ML research on real market data")

        return results

    except Exception as e:
        print(f"\n‚ùå Error: {e}")
        import traceback
        traceback.print_exc()
        return None

if __name__ == "__main__":
    results = main()

    if results:
        print(f"\nüíæ Results available in Python session")
        sys.exit(0)
    else:
        sys.exit(1)
